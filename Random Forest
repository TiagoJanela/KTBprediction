import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import export_graphviz
import pydot
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.externals import joblib
from sklearn import metrics
import pickle
from sklearn.model_selection import train_test_split
from scipy.stats import spearmanr, pearsonr
from sklearn.ensemble import RandomForestRegressor




pathmodel="C:/Users/tiago/source/repos/RF_TRAIN_FIT_V2/"
pathdB='T:/OneDrive - Universidade de Lisboa/Database_LOGKTB/RF/dB/'
path_results = "T:/OneDrive - Universidade de Lisboa/Database_LOGKTB/RF/RFresults/"

filenameTR='TR_bp1169.xlsx'
filenameTE='TE_bp0291.xlsx'
filenameTR_pred="TR_bp1169_NEW_DATA_RF_MW.xlsx"
filenameTE_pred="TE_bp0291_NEW_DATA_RF_MW.xlsx"
filenameTR_metrics = "TR_bp1169_metrics_RF_MW.xlsx"
filenameTE_metrics= "TE_bp0291_metrics_RF_MW.xlsx"
filenameVarImportance = "bp0291_Importances_RF_MW.xlsx"

features = pd.read_excel(pathdB+filenameTR)    
print(features.head())


train_labels = features['LOGKTB']
features = features.drop('LOGKTB', axis=1) 

train_mol_name = features["MOL_NAMES"]
train_mol_name_drop = features.drop("MOL_NAMES", axis=1, inplace=True)  

train = features





# Create the model 
nestimators = 100      
maxfeatures = "auto"
maxdepth = 10
bootstrap_var = False
minsamplesleaf = 4 
minsamplessplit = 5 



model = RandomForestRegressor(n_estimators= nestimators,        #n_estimators = n trees
                            max_features = maxfeatures ,
                            max_depth = maxdepth, 
                            bootstrap = bootstrap_var, 
                            min_samples_leaf = minsamplesleaf, 
                            min_samples_split = minsamplessplit
                           
                            )
                                


model.fit(train, train_labels)




#Tells the model to predict the train
pred_train = model.predict(train) 



#Results_TR

TR_results = pd.DataFrame(list(zip(train_mol_name, train_labels,pred_train)), columns=["Mol_Names","Observed_TR", "Predicted_TR"])         #gives the predicted value,the obeserved value for train

print(TR_results)

export_excel_TR = TR_results.to_excel (path_results+filenameTR_pred, index = None, header=True)



#  Metrics _TR

MSE = mean_squared_error(train_labels, pred_train)                                                     
RMSE = np.sqrt(MSE)  
MAE =  metrics.mean_absolute_error(train_labels, pred_train)              
msg = "%s = %.5f" % (model, round(RMSE, 5))
print('RMSE of', msg)                                          #Prints RMSE for train 
print('Mean Absolute Error:', MAE)                             #Prints MAE for train         
TR_score = r2_score(train_labels, pred_train)   
print(f'Train data R-2 score: {TR_score:>5.9}')  

metrics_MSE_TR = {MSE}
metrics_R2_TR = {TR_score}
metrics_RMSE_TR = {RMSE}
metrics_MAE_TR = {MAE}




metrics_model_TR = pd.DataFrame(list(zip(metrics_MSE_TR, metrics_RMSE_TR, metrics_MAE_TR, metrics_R2_TR)), columns=["MSE","RMSE","MAE","R2"])

export_excel_TR = metrics_model_TR.to_excel (path_results+filenameTR_metrics, index = None, header=True)



#VarImportance

# Get numerical feature importances 
feature_list = list(features.columns)                                                                                              

# Get numerical feature importances                                                                                               
importances = list(model.feature_importances_)

# List of tuples with variable and importance
feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_list, importances)]

# Sort the feature importances by most important first
feature_importances_sort = sorted(feature_importances, key = lambda x: x[1], reverse = True)

feature_importances_save = pd.DataFrame(list(feature_importances_sort), columns=["Feature_Name","Importance"])

export_excel_Importances = feature_importances_save.to_excel (path_results+filenameVarImportance, index = None, header=True)





#TEST

features_test = pd.read_excel(pathdB+filenameTE)

test_labels = features_test["LOGKTB"]
test_labels_drop = features_test.drop('LOGKTB', axis=1, inplace=True)

test_mol_name = features_test["MOL_NAMES"]
test_mol_name_drop = features_test.drop("MOL_NAMES", axis=1, inplace=True) 

test = features_test


#Predict TEST
pred_test = model.predict(test)

#Results_TE

TE_results = pd.DataFrame(list(zip(test_mol_name,test_labels, pred_test)), columns=["Mol_Name","Observed TE","Predicted TE"])           #gives me the predicted value,the actual value for train
print(TE_results)

export_excel_TE = TE_results.to_excel (path_results+filenameTE_pred, index = None, header=True)



#Metrics_TE

MSE = mean_squared_error(test_labels, pred_test)                                               #MSE         
RMSE = np.sqrt(MSE)  
MAE =  metrics.mean_absolute_error(test_labels, pred_test)              
msg = "%s = %.5f" % (model, round(RMSE, 5))
print('RMSE of', msg)                          #Prints RMSE for test
print('Mean Absolute Error:', MAE)             #Prints MAE for test         

TE_score = r2_score(test_labels, pred_test)   
print(f'TEST data R-2 score: {TE_score:>5.9}')  

metrics_MSE_TE = {MSE}
metrics_R2_TE = {TE_score}
metrics_RMSE_TE = {RMSE}
metrics_MAE_TE = {MAE}


metrics_model_TE = pd.DataFrame(list(zip(metrics_MSE_TE, metrics_R2_TE, metrics_RMSE_TE, metrics_MAE_TE)), columns=["MSE","RMSE","MAE","R2"])

export_excel_TE = metrics_model_TE.to_excel (path_results+filenameTE_metrics, index = None, header=True) 


#This command is the one that saves the model and the file:"'RF_LogKtb(0,1)Molecular Descriptors(0,1)_RF.pkl" its located in the model folder   
joblib.dump(model, 'RF_LogKtb(0,1)Molecular Descriptors(0,1)_RF.pkl')
